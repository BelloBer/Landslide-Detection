from google.colab import drive
drive.mount('/content/drive')
# Import necessary libraries
import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input
from tensorflow.keras import backend as K
import tensorflow as tf
from tensorflow.keras.utils import Sequence
from tensorflow.keras.preprocessing.image import ImageDataGenerator
# Define paths for the dataset (remember to unzip the dataset first!)
#train_csv_path = 'data/Train.csv'  # Path to the training labels CSV file
#test_csv_path = 'data/Test.csv'    # Path to the test image IDs CSV file
#train_data_path = 'data/train_data'  # Folder where .npy train files are located
#test_data_path = 'data/test_data'    # Folder where .npy test files are located

#new ecode entry, trying to mount google drive

train_data = '/content/drive/My Drive/train_data1/'
test_data = '/content/drive/My Drive/test_data/'

train_csv = "/content/drive/My Drive/train_data1/Train.csv"
test_csv = "/content/drive/My Drive/test_data/Test.csv"


# Load Train.csv and inspect the data
train_df = pd.read_csv(train_csv)
print("Train.csv:")
print(train_df.head())

# Check distribution of labels
label_counts = train_df['label'].value_counts()
labels = ['No Landslide', 'Landslide']  # Map the labels 0 and 1 to descriptive names

plt.figure(figsize=(6, 4))
plt.bar(labels, label_counts.values, color=['skyblue', 'salmon'])
plt.xlabel("Class Label")
plt.ylabel("Frequency")
plt.title("Distribution of Labels in Training Set")
plt.show()

# Update these paths to match your Google Drive structure
train_data_path = '/content/drive/My Drive/train_data1/'  # Folder with .npy files
test_data_path = '/content/drive/My Drive/test_data/'    # Folder with test .npy files

# Modified function to handle SAR data better
def load_and_normalize_npy_image(image_id, folder_path):
    image_path = os.path.join(folder_path, f"{image_id}.npy")
    img = np.load(image_path)
    img_normalized = np.zeros_like(img, dtype=np.float32)

    # Optical bands (0-3)
    for band in range(4):
        img_normalized[:,:,band] = (img[:,:,band] - img[:,:,band].min()) / \
                                 (img[:,:,band].max() - img[:,:,band].min() + 1e-6)

    # SAR bands (4-11)
    for band in range(4, 12):
        # SAFE dB conversion
        sar_data = img[:,:,band]

        # Method 1: Absolute value (recommended)
        sar_positive = np.abs(sar_data)
        img_dB = 10 * np.log10(sar_positive + 1e-6)

        # Alternative if you know data type:
        # if amplitude data: sar_positive = sar_data**2
        # if intensity data: sar_positive = sar_data

        # Normalize dB values
        img_normalized[:,:,band] = (img_dB - img_dB.min()) / \
                                 (img_dB.max() - img_dB.min() + 1e-6)

    return img_normalized

# Band descriptions (updated with more details)
band_descriptions = [
    "Red (Optical)",
    "Green (Optical)",
    "Blue (Optical)",
    "Near Infrared (Optical)",
    "Descending VV (SAR)",
    "Descending VH (SAR)",
    "Descending Diff VV (SAR Change)",
    "Descending Diff VH (SAR Change)",
    "Ascending VV (SAR)",
    "Ascending VH (SAR)",
    "Ascending Diff VV (SAR Change)",
    "Ascending Diff VH (SAR Change)"
]

# Get 2 random samples (ensure they exist in the folder)
available_ids = [f.split('.')[0] for f in os.listdir(train_data_path) if f.endswith('.npy')]
example_ids = np.random.choice(available_ids, 2, replace=False)

for image_id in example_ids:
    try:
        img_normalized = load_and_normalize_npy_image(image_id, train_data_path)

        # Plot all 12 bands in a 3x4 grid
        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        fig.suptitle(f"Sample Image ID: {image_id} - All 12 Bands", fontsize=16, y=1.02)

        for band in range(12):
            row = band // 4
            col = band % 4
            axes[row, col].imshow(img_normalized[:, :, band], cmap='viridis')
            axes[row, col].set_title(f"Band {band+1}: {band_descriptions[band]}", fontsize=10)
            axes[row, col].axis('off')

        plt.tight_layout()
        plt.show()

    except Exception as e:
        print(f"Could not process {image_id}: {str(e)}")
        continue
