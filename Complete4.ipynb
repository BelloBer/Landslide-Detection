{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BelloBer/Landslide-Detection/blob/main/Complete4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kCjB3OQQOWk"
      },
      "source": [
        "#Complete4\n",
        "* removed resizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kye3tVK6QBr7",
        "outputId": "2bea93d0-7844-40f7-818c-09e472c5406a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Using GPU for training\n",
            "Dataset Info:\n",
            "Total samples: 7147\n",
            "Class distribution:\n",
            "label\n",
            "0    5892\n",
            "1    1255\n",
            "Name: count, dtype: int64\n",
            "Class ratio: 0.213\n",
            "Class weights: {0: np.float64(0.6065003394433129), 1: np.float64(2.847410358565737)}\n",
            "Valid files: 5717/5717\n",
            "Valid files: 1430/1430\n",
            "Detecting image shape...\n",
            "Using input shape: (64, 64, 12)\n",
            "Creating model with input shape: (64, 64, 12)\n",
            "Model parameters: 2,138,465\n",
            "Starting training...\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.6385 - balanced_f1_score: 0.4603 - loss: 0.5903 - precision_m: 1.3312 - recall_m: 1.9580\n",
            "Epoch 1: val_balanced_f1_score improved from -inf to 0.46964, saving model to best_landslide_model.keras\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 121ms/step - accuracy: 0.6386 - balanced_f1_score: 0.4603 - loss: 0.5903 - precision_m: 1.3312 - recall_m: 1.9575 - val_accuracy: 0.8462 - val_balanced_f1_score: 0.4696 - val_loss: 0.5393 - val_precision_m: 0.7374 - val_recall_m: 0.5140 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7462 - balanced_f1_score: 0.4751 - loss: 0.4777 - precision_m: 1.4040 - recall_m: 1.4228\n",
            "Epoch 2: val_balanced_f1_score did not improve from 0.46964\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 85ms/step - accuracy: 0.7462 - balanced_f1_score: 0.4751 - loss: 0.4777 - precision_m: 1.4039 - recall_m: 1.4227 - val_accuracy: 0.8287 - val_balanced_f1_score: 0.4518 - val_loss: 0.4999 - val_precision_m: 0.1285 - val_recall_m: 0.0615 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7407 - balanced_f1_score: 0.4692 - loss: 0.4198 - precision_m: 1.2939 - recall_m: 1.3116\n",
            "Epoch 3: val_balanced_f1_score improved from 0.46964 to 0.48072, saving model to best_landslide_model.keras\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 87ms/step - accuracy: 0.7407 - balanced_f1_score: 0.4692 - loss: 0.4198 - precision_m: 1.2940 - recall_m: 1.3117 - val_accuracy: 0.8427 - val_balanced_f1_score: 0.4807 - val_loss: 0.3975 - val_precision_m: 1.3296 - val_recall_m: 1.4916 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7638 - balanced_f1_score: 0.4741 - loss: 0.3925 - precision_m: 1.3627 - recall_m: 1.3584\n",
            "Epoch 4: val_balanced_f1_score did not improve from 0.48072\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 102ms/step - accuracy: 0.7637 - balanced_f1_score: 0.4741 - loss: 0.3924 - precision_m: 1.3627 - recall_m: 1.3584 - val_accuracy: 0.8497 - val_balanced_f1_score: 0.4676 - val_loss: 0.4085 - val_precision_m: 0.6648 - val_recall_m: 0.3855 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7812 - balanced_f1_score: 0.4751 - loss: 0.3533 - precision_m: 1.4189 - recall_m: 1.5137\n",
            "Epoch 5: val_balanced_f1_score did not improve from 0.48072\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 87ms/step - accuracy: 0.7812 - balanced_f1_score: 0.4751 - loss: 0.3533 - precision_m: 1.4188 - recall_m: 1.5136 - val_accuracy: 0.5385 - val_balanced_f1_score: 0.3728 - val_loss: 0.4430 - val_precision_m: 1.4022 - val_recall_m: 4.1508 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 6/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7698 - balanced_f1_score: 0.4737 - loss: 0.3336 - precision_m: 1.4128 - recall_m: 1.4608\n",
            "Epoch 6: val_balanced_f1_score did not improve from 0.48072\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 88ms/step - accuracy: 0.7698 - balanced_f1_score: 0.4737 - loss: 0.3336 - precision_m: 1.4128 - recall_m: 1.4608 - val_accuracy: 0.8301 - val_balanced_f1_score: 0.4777 - val_loss: 0.3474 - val_precision_m: 1.0950 - val_recall_m: 0.9553 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 7/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7643 - balanced_f1_score: 0.4713 - loss: 0.3262 - precision_m: 1.4070 - recall_m: 1.4200\n",
            "Epoch 7: val_balanced_f1_score did not improve from 0.48072\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 87ms/step - accuracy: 0.7643 - balanced_f1_score: 0.4713 - loss: 0.3262 - precision_m: 1.4070 - recall_m: 1.4200 - val_accuracy: 0.8196 - val_balanced_f1_score: 0.4766 - val_loss: 0.3179 - val_precision_m: 1.3352 - val_recall_m: 1.7709 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 8/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7822 - balanced_f1_score: 0.4759 - loss: 0.2986 - precision_m: 1.3434 - recall_m: 1.3781\n",
            "Epoch 8: val_balanced_f1_score improved from 0.48072 to 0.48582, saving model to best_landslide_model.keras\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 89ms/step - accuracy: 0.7822 - balanced_f1_score: 0.4759 - loss: 0.2986 - precision_m: 1.3434 - recall_m: 1.3781 - val_accuracy: 0.8755 - val_balanced_f1_score: 0.4858 - val_loss: 0.2968 - val_precision_m: 1.3408 - val_recall_m: 1.6145 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 9/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7543 - balanced_f1_score: 0.4723 - loss: 0.3091 - precision_m: 1.3908 - recall_m: 1.3755\n",
            "Epoch 9: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 85ms/step - accuracy: 0.7543 - balanced_f1_score: 0.4723 - loss: 0.3091 - precision_m: 1.3908 - recall_m: 1.3755 - val_accuracy: 0.8587 - val_balanced_f1_score: 0.4831 - val_loss: 0.3017 - val_precision_m: 1.2682 - val_recall_m: 1.3575 - learning_rate: 0.0010\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 10/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7778 - balanced_f1_score: 0.4747 - loss: 0.3055 - precision_m: 1.3247 - recall_m: 1.4001\n",
            "Epoch 10: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 86ms/step - accuracy: 0.7778 - balanced_f1_score: 0.4747 - loss: 0.3055 - precision_m: 1.3248 - recall_m: 1.4000 - val_accuracy: 0.8713 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 0.0010\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0005000000237487257.\n",
            "Epoch 11/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7690 - balanced_f1_score: nan - loss: nan - precision_m: nan - recall_m: nan\n",
            "Epoch 11: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 89ms/step - accuracy: 0.7690 - balanced_f1_score: nan - loss: nan - precision_m: nan - recall_m: nan - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 5.0000e-04\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0002500000118743628.\n",
            "Epoch 12/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7887 - balanced_f1_score: 0.4767 - loss: 0.2807 - precision_m: 1.3418 - recall_m: 1.3680\n",
            "Epoch 12: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 92ms/step - accuracy: 0.7887 - balanced_f1_score: 0.4767 - loss: 0.2807 - precision_m: 1.3419 - recall_m: 1.3680 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 2.5000e-04\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0001250000059371814.\n",
            "Epoch 13/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7714 - balanced_f1_score: 0.4774 - loss: 0.2851 - precision_m: 1.4728 - recall_m: 1.5027\n",
            "Epoch 13: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 88ms/step - accuracy: 0.7714 - balanced_f1_score: 0.4774 - loss: 0.2850 - precision_m: 1.4727 - recall_m: 1.5026 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 1.2500e-04\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 6.25000029685907e-05.\n",
            "Epoch 14/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7905 - balanced_f1_score: 0.4773 - loss: 0.2681 - precision_m: 1.4235 - recall_m: 1.4254\n",
            "Epoch 14: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 87ms/step - accuracy: 0.7905 - balanced_f1_score: 0.4773 - loss: 0.2681 - precision_m: 1.4235 - recall_m: 1.4254 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 6.2500e-05\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 3.125000148429535e-05.\n",
            "Epoch 15/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7806 - balanced_f1_score: 0.4730 - loss: 0.2768 - precision_m: 1.4110 - recall_m: 1.3599\n",
            "Epoch 15: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 86ms/step - accuracy: 0.7806 - balanced_f1_score: 0.4730 - loss: 0.2768 - precision_m: 1.4110 - recall_m: 1.3600 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 3.1250e-05\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 1.5625000742147677e-05.\n",
            "Epoch 16/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7761 - balanced_f1_score: 0.4763 - loss: 0.2602 - precision_m: 1.4393 - recall_m: 1.5012\n",
            "Epoch 16: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 102ms/step - accuracy: 0.7761 - balanced_f1_score: 0.4763 - loss: 0.2602 - precision_m: 1.4393 - recall_m: 1.5011 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 1.5625e-05\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 7.812500371073838e-06.\n",
            "Epoch 17/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7895 - balanced_f1_score: 0.4743 - loss: 0.2647 - precision_m: 1.3872 - recall_m: 1.4915\n",
            "Epoch 17: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 86ms/step - accuracy: 0.7895 - balanced_f1_score: 0.4743 - loss: 0.2647 - precision_m: 1.3872 - recall_m: 1.4915 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 7.8125e-06\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 3.906250185536919e-06.\n",
            "Epoch 18/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8017 - balanced_f1_score: 0.4765 - loss: 0.2529 - precision_m: 1.3867 - recall_m: 1.4822\n",
            "Epoch 18: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 87ms/step - accuracy: 0.8017 - balanced_f1_score: 0.4765 - loss: 0.2529 - precision_m: 1.3867 - recall_m: 1.4822 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 3.9063e-06\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 1.9531250927684596e-06.\n",
            "Epoch 19/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8010 - balanced_f1_score: 0.4767 - loss: 0.2580 - precision_m: 1.3756 - recall_m: 1.4107\n",
            "Epoch 19: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 86ms/step - accuracy: 0.8010 - balanced_f1_score: 0.4767 - loss: 0.2580 - precision_m: 1.3756 - recall_m: 1.4108 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 1.9531e-06\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 9.765625463842298e-07.\n",
            "Epoch 20/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8136 - balanced_f1_score: 0.4748 - loss: 0.2603 - precision_m: 1.3475 - recall_m: 1.4296\n",
            "Epoch 20: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 87ms/step - accuracy: 0.8136 - balanced_f1_score: 0.4748 - loss: 0.2603 - precision_m: 1.3476 - recall_m: 1.4296 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 9.7656e-07\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 2.4414063659605745e-07.\n",
            "Epoch 21/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.7988 - balanced_f1_score: 0.4751 - loss: 0.2655 - precision_m: 1.4086 - recall_m: 1.4614\n",
            "Epoch 21: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 88ms/step - accuracy: 0.7987 - balanced_f1_score: 0.4751 - loss: 0.2655 - precision_m: 1.4086 - recall_m: 1.4614 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 2.4414e-07\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 6.103515914901436e-08.\n",
            "Epoch 22/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7829 - balanced_f1_score: 0.4762 - loss: 0.2607 - precision_m: 1.4642 - recall_m: 1.4351\n",
            "Epoch 22: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 86ms/step - accuracy: 0.7829 - balanced_f1_score: 0.4762 - loss: 0.2607 - precision_m: 1.4641 - recall_m: 1.4351 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 6.1035e-08\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 1.525878978725359e-08.\n",
            "Epoch 23/50\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7776 - balanced_f1_score: 0.4746 - loss: 0.2638 - precision_m: 1.4214 - recall_m: 1.5459\n",
            "Epoch 23: val_balanced_f1_score did not improve from 0.48582\n",
            "\u001b[1m715/715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 86ms/step - accuracy: 0.7776 - balanced_f1_score: 0.4746 - loss: 0.2638 - precision_m: 1.4213 - recall_m: 1.5459 - val_accuracy: 0.8245 - val_balanced_f1_score: nan - val_loss: nan - val_precision_m: nan - val_recall_m: nan - learning_rate: 1.5259e-08\n",
            "Epoch 23: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "Optimizing decision threshold...\n",
            "\n",
            "Optimal threshold: 0.500\n",
            "Best metrics: {'f1_macro': 0.8034355153581931, 'f1_positive': 0.6843971631205674, 'f1_negative': 0.9224738675958188, 'balanced_score': 0.7558201744631428}\n",
            "\n",
            "Final Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "No Landslide       0.95      0.90      0.92      1179\n",
            "   Landslide       0.62      0.77      0.68       251\n",
            "\n",
            "    accuracy                           0.88      1430\n",
            "   macro avg       0.78      0.83      0.80      1430\n",
            "weighted avg       0.89      0.88      0.88      1430\n",
            "\n",
            "Generating test predictions...\n"
          ]
        }
      ],
      "source": [
        "# Improved Landslide Detection Model\n",
        "# Fixed learning rate scheduling and optimized for better performance\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (Dense, Flatten, Conv2D, MaxPooling2D, Dropout,\n",
        "                                   BatchNormalization, Input, GlobalAveragePooling2D,\n",
        "                                   SeparableConv2D, Add, Activation, MultiHeadAttention,\n",
        "                                   LayerNormalization, Reshape, Concatenate)\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,\n",
        "                                       TensorBoard, LearningRateScheduler)\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import datetime\n",
        "import gc\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure TensorFlow is using GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(\"Using GPU for training\")\n",
        "else:\n",
        "    print(\"Warning: No GPU detected, using CPU instead\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Enable mixed precision for better performance\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Define paths\n",
        "train_data_path = '/content/drive/My Drive/train_data/'\n",
        "test_data_path = '/content/drive/My Drive/test_data/'\n",
        "train_csv = \"/content/drive/My Drive/train_data/Train.csv\"\n",
        "test_csv = \"/content/drive/My Drive/test_data/Test.csv\"\n",
        "\n",
        "# Load and analyze data\n",
        "train_df = pd.read_csv(train_csv)\n",
        "print(\"Dataset Info:\")\n",
        "print(f\"Total samples: {len(train_df)}\")\n",
        "print(f\"Class distribution:\\n{train_df['label'].value_counts()}\")\n",
        "print(f\"Class ratio: {train_df['label'].value_counts()[1] / train_df['label'].value_counts()[0]:.3f}\")\n",
        "\n",
        "# Optimized image loading function\n",
        "def load_and_preprocess_image(image_id, folder_path):\n",
        "    \"\"\"Load and preprocess image with robust error handling\"\"\"\n",
        "    try:\n",
        "        image_path = os.path.join(folder_path, f\"{image_id}.npy\")\n",
        "        img = np.load(image_path).astype(np.float32)\n",
        "\n",
        "        if len(img.shape) != 3 or img.shape[2] != 12:\n",
        "            return None\n",
        "\n",
        "        # Create output array\n",
        "        processed_img = np.zeros_like(img, dtype=np.float32)\n",
        "\n",
        "        # Process optical bands (0-3) with enhanced normalization\n",
        "        for band in range(4):\n",
        "            band_data = img[:, :, band]\n",
        "\n",
        "            # Remove outliers using percentile clipping\n",
        "            p2, p98 = np.percentile(band_data, [2, 98])\n",
        "            band_data = np.clip(band_data, p2, p98)\n",
        "\n",
        "            # Normalize to [0, 1]\n",
        "            if band_data.max() > band_data.min():\n",
        "                processed_img[:, :, band] = (band_data - band_data.min()) / (band_data.max() - band_data.min())\n",
        "            else:\n",
        "                processed_img[:, :, band] = 0.5\n",
        "\n",
        "        # Process SAR bands (4-11) with improved handling\n",
        "        for band in range(4, 12):\n",
        "            sar_data = img[:, :, band]\n",
        "\n",
        "            # Convert to dB scale with better handling of negative values\n",
        "            sar_linear = np.abs(sar_data) + 1e-10\n",
        "            sar_db = 10 * np.log10(sar_linear)\n",
        "\n",
        "            # Clip extreme values\n",
        "            p1, p99 = np.percentile(sar_db, [1, 99])\n",
        "            sar_db = np.clip(sar_db, p1, p99)\n",
        "\n",
        "            # Normalize\n",
        "            if sar_db.max() > sar_db.min():\n",
        "                processed_img[:, :, band] = (sar_db - sar_db.min()) / (sar_db.max() - sar_db.min())\n",
        "            else:\n",
        "                processed_img[:, :, band] = 0.5\n",
        "\n",
        "        return processed_img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {image_id}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Enhanced data generator\n",
        "class EnhancedLandslideGenerator(Sequence):\n",
        "    def __init__(self, image_ids, labels, folder_path, batch_size=16,\n",
        "                 augment=False, shuffle=True, mixup_alpha=0.2):\n",
        "        super().__init__()\n",
        "        self.image_ids = image_ids\n",
        "        self.labels = labels\n",
        "        self.folder_path = folder_path\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "        self.shuffle = shuffle\n",
        "        self.mixup_alpha = mixup_alpha\n",
        "\n",
        "        # Validate files\n",
        "        self.valid_indices = self._validate_files()\n",
        "        print(f\"Valid files: {len(self.valid_indices)}/{len(self.image_ids)}\")\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def _validate_files(self):\n",
        "        valid_indices = []\n",
        "        for idx, img_id in enumerate(self.image_ids):\n",
        "            file_path = os.path.join(self.folder_path, f\"{img_id}.npy\")\n",
        "            if os.path.exists(file_path):\n",
        "                try:\n",
        "                    test_img = np.load(file_path)\n",
        "                    if len(test_img.shape) == 3 and test_img.shape[2] == 12:\n",
        "                        valid_indices.append(idx)\n",
        "                except:\n",
        "                    continue\n",
        "        return valid_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.valid_indices) / self.batch_size))\n",
        "\n",
        "    def custom_augment(self, img):\n",
        "        \"\"\"Custom augmentation for multi-channel images\"\"\"\n",
        "        if not self.augment:\n",
        "            return img\n",
        "\n",
        "        # Random horizontal flip\n",
        "        if np.random.random() < 0.5:\n",
        "            img = np.flip(img, axis=1)\n",
        "\n",
        "        # Random vertical flip\n",
        "        if np.random.random() < 0.5:\n",
        "            img = np.flip(img, axis=0)\n",
        "\n",
        "        # Random rotation (90, 180, 270 degrees)\n",
        "        if np.random.random() < 0.5:\n",
        "            k = np.random.randint(1, 4)\n",
        "            img = np.rot90(img, k=k, axes=(0, 1))\n",
        "\n",
        "        # Random brightness adjustment (only for optical bands 0-3)\n",
        "        if np.random.random() < 0.3:\n",
        "            brightness_factor = np.random.uniform(0.8, 1.2)\n",
        "            img[:, :, :4] = np.clip(img[:, :, :4] * brightness_factor, 0, 1)\n",
        "\n",
        "        # Light random noise\n",
        "        if np.random.random() < 0.2:\n",
        "            noise = np.random.normal(0, 0.005, img.shape).astype(np.float32)\n",
        "            img = np.clip(img + noise, 0, 1)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def mixup(self, x1, x2, y1, y2, alpha):\n",
        "        \"\"\"Apply mixup augmentation\"\"\"\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        mixed_x = lam * x1 + (1 - lam) * x2\n",
        "        mixed_y = lam * y1 + (1 - lam) * y2\n",
        "        return mixed_x, mixed_y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.valid_indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            img_id = self.image_ids[i]\n",
        "            label = self.labels[i]\n",
        "\n",
        "            img = load_and_preprocess_image(img_id, self.folder_path)\n",
        "            if img is not None:\n",
        "                img = self.custom_augment(img)\n",
        "                batch_images.append(img)\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        if len(batch_images) == 0:\n",
        "            # Get actual image shape from first valid image\n",
        "            sample_shape = self._get_sample_shape()\n",
        "            batch_images = [np.zeros(sample_shape, dtype=np.float32)]\n",
        "            batch_labels = [0]\n",
        "\n",
        "        batch_images = np.array(batch_images, dtype=np.float32)\n",
        "        batch_labels = np.array(batch_labels, dtype=np.float32)\n",
        "\n",
        "        # Apply mixup for training\n",
        "        if self.augment and len(batch_images) >= 2 and np.random.random() < 0.3:\n",
        "            indices = np.random.permutation(len(batch_images))\n",
        "            mixed_images, mixed_labels = self.mixup(\n",
        "                batch_images, batch_images[indices],\n",
        "                batch_labels, batch_labels[indices],\n",
        "                self.mixup_alpha\n",
        "            )\n",
        "            return mixed_images, mixed_labels\n",
        "\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def _get_sample_shape(self):\n",
        "        \"\"\"Get the shape of the first valid image\"\"\"\n",
        "        for i in self.valid_indices[:10]:  # Check first 10 valid indices\n",
        "            img_id = self.image_ids[i]\n",
        "            img = load_and_preprocess_image(img_id, self.folder_path)\n",
        "            if img is not None:\n",
        "                return img.shape\n",
        "        return (64, 64, 12)  # Default fallback\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.valid_indices)\n",
        "\n",
        "# Enhanced metrics\n",
        "def balanced_f1_score(y_true, y_pred):\n",
        "    \"\"\"Calculate balanced F1 score considering both classes\"\"\"\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "\n",
        "    # F1 for positive class\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
        "\n",
        "    precision_pos = tp / (tp + fp + K.epsilon())\n",
        "    recall_pos = tp / (tp + fn + K.epsilon())\n",
        "    f1_pos = 2 * precision_pos * recall_pos / (precision_pos + recall_pos + K.epsilon())\n",
        "\n",
        "    # F1 for negative class\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    precision_neg = tn / (tn + fn + K.epsilon())\n",
        "    recall_neg = tn / (tn + fp + K.epsilon())\n",
        "    f1_neg = 2 * precision_neg * recall_neg / (precision_neg + recall_neg + K.epsilon())\n",
        "\n",
        "    # Return macro F1\n",
        "    return (f1_pos + f1_neg) / 2\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_pred = K.round(K.clip(y_pred, 0, 1))\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return tp / (predicted_positives + K.epsilon())\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    y_pred = K.round(K.clip(y_pred, 0, 1))\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return tp / (possible_positives + K.epsilon())\n",
        "\n",
        "# Enhanced loss functions\n",
        "def focal_loss(gamma=2.0, alpha=0.75):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        y_true = K.cast(y_true, 'float32')\n",
        "        y_pred = K.cast(K.clip(y_pred, K.epsilon(), 1 - K.epsilon()), 'float32')\n",
        "\n",
        "        ce_loss = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        focal_weight = alpha * K.pow(1 - p_t, gamma)\n",
        "\n",
        "        return K.mean(focal_weight * ce_loss)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    \"\"\"Combine focal loss with dice loss for better performance\"\"\"\n",
        "    focal = focal_loss(gamma=2.0, alpha=0.75)(y_true, y_pred)\n",
        "\n",
        "    # Dice loss component\n",
        "    smooth = 1e-6\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    dice_coeff = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    dice_loss = 1 - dice_coeff\n",
        "\n",
        "    return focal + 0.3 * dice_loss\n",
        "\n",
        "# Enhanced model architecture\n",
        "def create_enhanced_model(input_shape):\n",
        "    \"\"\"Create an enhanced CNN with attention mechanism\"\"\"\n",
        "    print(f\"Creating model with input shape: {input_shape}\")\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv block\n",
        "    x = Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    def residual_block(x, filters, downsample=False):\n",
        "        shortcut = x\n",
        "        stride = 2 if downsample else 1\n",
        "\n",
        "        x = Conv2D(filters, (3, 3), strides=stride, padding='same',\n",
        "                   kernel_regularizer=l2(1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = Conv2D(filters, (3, 3), padding='same',\n",
        "                   kernel_regularizer=l2(1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        if downsample or shortcut.shape[-1] != filters:\n",
        "            shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same',\n",
        "                             kernel_regularizer=l2(1e-4))(shortcut)\n",
        "            shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "        x = Add()([x, shortcut])\n",
        "        x = Activation('relu')(x)\n",
        "        x = Dropout(0.1)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # Adaptive feature extraction based on input size\n",
        "    current_size = input_shape[0]\n",
        "\n",
        "    if current_size >= 256:\n",
        "        # Full architecture for large images\n",
        "        x = residual_block(x, 64, downsample=True)   # /2\n",
        "        x = residual_block(x, 64)\n",
        "        x = residual_block(x, 128, downsample=True)  # /4\n",
        "        x = residual_block(x, 128)\n",
        "        x = residual_block(x, 256, downsample=True)  # /8\n",
        "        x = residual_block(x, 256)\n",
        "        x = residual_block(x, 512, downsample=True)  # /16\n",
        "    elif current_size >= 128:\n",
        "        # Medium architecture\n",
        "        x = residual_block(x, 64, downsample=True)   # /2\n",
        "        x = residual_block(x, 128, downsample=True)  # /4\n",
        "        x = residual_block(x, 256, downsample=True)  # /8\n",
        "        x = residual_block(x, 512, downsample=True)  # /16\n",
        "    else:\n",
        "        # Smaller architecture for small images (64x64)\n",
        "        x = residual_block(x, 64, downsample=True)   # /2 -> 32x32\n",
        "        x = residual_block(x, 128, downsample=True)  # /4 -> 16x16\n",
        "        x = residual_block(x, 256)                   # 16x16\n",
        "\n",
        "    # Simplified attention mechanism (optional, remove if causing issues)\n",
        "    try:\n",
        "        # Get current spatial dimensions\n",
        "        spatial_dims = x.shape[1] * x.shape[2]\n",
        "        channels = x.shape[3]\n",
        "\n",
        "        # Only apply attention if we have reasonable dimensions\n",
        "        if spatial_dims >= 4 and spatial_dims <= 1024 and channels >= 8:\n",
        "            # Reshape for attention\n",
        "            x_reshaped = Reshape((spatial_dims, channels))(x)\n",
        "\n",
        "            # Multi-head attention with reduced complexity\n",
        "            attention_output = MultiHeadAttention(\n",
        "                num_heads=min(8, channels // 8),\n",
        "                key_dim=min(64, channels // 4),\n",
        "                dropout=0.1\n",
        "            )(x_reshaped, x_reshaped)\n",
        "\n",
        "            attention_output = LayerNormalization()(attention_output + x_reshaped)\n",
        "\n",
        "            # Reshape back\n",
        "            x_attended = Reshape((x.shape[1], x.shape[2], channels))(attention_output)\n",
        "\n",
        "            # Combine original and attended features\n",
        "            x = Concatenate()([x, x_attended])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Attention mechanism failed, using standard processing: {e}\")\n",
        "\n",
        "    # Final processing\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    outputs = Dense(1, activation='sigmoid', dtype='float32', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare data with stratified split\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(train_df)),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_df['label']\n",
        ")\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_df['label']),\n",
        "    y=train_df['label']\n",
        ")\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "print(f\"Class weights: {class_weight_dict}\")\n",
        "\n",
        "# Create generators\n",
        "train_gen = EnhancedLandslideGenerator(\n",
        "    image_ids=train_df['ID'].values[train_idx],\n",
        "    labels=train_df['label'].values[train_idx],\n",
        "    folder_path=train_data_path,\n",
        "    batch_size=8,\n",
        "    augment=True,\n",
        "    mixup_alpha=0.2\n",
        ")\n",
        "\n",
        "val_gen = EnhancedLandslideGenerator(\n",
        "    image_ids=train_df['ID'].values[val_idx],\n",
        "    labels=train_df['label'].values[val_idx],\n",
        "    folder_path=train_data_path,\n",
        "    batch_size=8,\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "# Detect actual image shape\n",
        "print(\"Detecting image shape...\")\n",
        "actual_shape = train_gen._get_sample_shape()\n",
        "print(f\"Using input shape: {actual_shape}\")\n",
        "\n",
        "# Create and compile model with correct input shape\n",
        "model = create_enhanced_model(actual_shape)\n",
        "\n",
        "# FIXED: Use simple Adam optimizer with fixed learning rate to avoid scheduling conflicts\n",
        "optimizer = Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=combined_loss,\n",
        "    metrics=['accuracy', precision_m, recall_m, balanced_f1_score]\n",
        ")\n",
        "\n",
        "print(f\"Model parameters: {model.count_params():,}\")\n",
        "\n",
        "# Custom learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    \"\"\"Custom learning rate schedule\"\"\"\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    elif epoch < 20:\n",
        "        return lr * 0.5\n",
        "    elif epoch < 30:\n",
        "        return lr * 0.25\n",
        "    else:\n",
        "        return lr * 0.1\n",
        "\n",
        "# Enhanced callbacks with fixed learning rate scheduling\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_landslide_model.keras',\n",
        "        monitor='val_balanced_f1_score',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_balanced_f1_score',\n",
        "        mode='max',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    LearningRateScheduler(scheduler, verbose=1)  # Use custom scheduler instead of ReduceLROnPlateau\n",
        "]\n",
        "\n",
        "# Train model\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Load best model\n",
        "model.load_weights('best_landslide_model.keras')\n",
        "\n",
        "# Enhanced threshold optimization\n",
        "print(\"Optimizing decision threshold...\")\n",
        "val_predictions = []\n",
        "val_labels = []\n",
        "\n",
        "for i in range(len(val_gen)):\n",
        "    batch_x, batch_y = val_gen[i]\n",
        "    pred_batch = model.predict(batch_x, verbose=0)\n",
        "    val_predictions.extend(pred_batch.flatten())\n",
        "    val_labels.extend(batch_y.flatten())\n",
        "\n",
        "y_probs = np.array(val_predictions)\n",
        "y_true = np.array(val_labels)\n",
        "\n",
        "# Grid search for optimal threshold\n",
        "thresholds = np.arange(0.1, 0.9, 0.005)\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "best_metrics = {}\n",
        "\n",
        "for thresh in thresholds:\n",
        "    y_pred = (y_probs > thresh).astype(int)\n",
        "\n",
        "    # Calculate metrics for both classes\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_pos = f1_score(y_true, y_pred, pos_label=1)\n",
        "    f1_neg = f1_score(y_true, y_pred, pos_label=0)\n",
        "\n",
        "    # Optimize for balanced performance\n",
        "    balanced_score = f1_macro * 0.6 + min(f1_pos, f1_neg) * 0.4\n",
        "\n",
        "    if balanced_score > best_f1:\n",
        "        best_f1 = balanced_score\n",
        "        best_thresh = thresh\n",
        "        best_metrics = {\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_positive': f1_pos,\n",
        "            'f1_negative': f1_neg,\n",
        "            'balanced_score': balanced_score\n",
        "        }\n",
        "\n",
        "print(f\"\\nOptimal threshold: {best_thresh:.3f}\")\n",
        "print(f\"Best metrics: {best_metrics}\")\n",
        "\n",
        "# Final evaluation\n",
        "y_pred_final = (y_probs > best_thresh).astype(int)\n",
        "print(f\"\\nFinal Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_final,\n",
        "                          target_names=['No Landslide', 'Landslide']))\n",
        "\n",
        "# Generate test predictions\n",
        "print(\"Generating test predictions...\")\n",
        "test_df = pd.read_csv(test_csv)\n",
        "test_predictions = []\n",
        "\n",
        "batch_size = 16\n",
        "for i in range(0, len(test_df), batch_size):\n",
        "    batch_ids = test_df['ID'].values[i:i+batch_size]\n",
        "    batch_imgs = []\n",
        "\n",
        "    for img_id in batch_ids:\n",
        "        img = load_and_preprocess_image(img_id, test_data_path)\n",
        "        if img is not None:\n",
        "            batch_imgs.append(img)\n",
        "        else:\n",
        "            batch_imgs.append(np.zeros(actual_shape, dtype=np.float32))\n",
        "\n",
        "    batch_imgs = np.array(batch_imgs)\n",
        "    probs = model.predict(batch_imgs, verbose=0).flatten()\n",
        "    preds = (probs > best_thresh).astype(int)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Create submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    'label': test_predictions\n",
        "})\n",
        "\n",
        "submission_df.to_csv('Enhanced_Landslide_Submission.csv', index=False)\n",
        "print(f\"Submission saved! Prediction distribution: {Counter(test_predictions)}\")\n",
        "\n",
        "# Plot training history\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['balanced_f1_score'], label='Training F1')\n",
        "plt.plot(history.history['val_balanced_f1_score'], label='Validation F1')\n",
        "plt.title('Model F1 Score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('F1 Score')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Cleanup\n",
        "gc.collect()\n",
        "print(\"Training completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BLOCK 1\n",
        "Loads and Training"
      ],
      "metadata": {
        "id": "XLjtpHsbcq3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Improved Landslide Detection Model\n",
        "# Fixed learning rate scheduling and optimized for better performance\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import f1_score, classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (Dense, Flatten, Conv2D, MaxPooling2D, Dropout,\n",
        "                                   BatchNormalization, Input, GlobalAveragePooling2D,\n",
        "                                   SeparableConv2D, Add, Activation, MultiHeadAttention,\n",
        "                                   LayerNormalization, Reshape, Concatenate)\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping, ReduceLROnPlateau,\n",
        "                                       TensorBoard, LearningRateScheduler)\n",
        "from tensorflow.keras.optimizers import Adam, AdamW\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import datetime\n",
        "import gc\n",
        "from collections import Counter\n",
        "\n",
        "# Ensure TensorFlow is using GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "    print(\"Using GPU for training\")\n",
        "else:\n",
        "    print(\"Warning: No GPU detected, using CPU instead\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Enable mixed precision for better performance\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "# Define paths\n",
        "train_data_path = '/content/drive/My Drive/train_data/'\n",
        "test_data_path = '/content/drive/My Drive/test_data/'\n",
        "train_csv = \"/content/drive/My Drive/train_data/Train.csv\"\n",
        "test_csv = \"/content/drive/My Drive/test_data/Test.csv\"\n",
        "\n",
        "# Load and analyze data\n",
        "train_df = pd.read_csv(train_csv)\n",
        "print(\"Dataset Info:\")\n",
        "print(f\"Total samples: {len(train_df)}\")\n",
        "print(f\"Class distribution:\\n{train_df['label'].value_counts()}\")\n",
        "print(f\"Class ratio: {train_df['label'].value_counts()[1] / train_df['label'].value_counts()[0]:.3f}\")\n",
        "\n",
        "# Optimized image loading function\n",
        "def load_and_preprocess_image(image_id, folder_path):\n",
        "    \"\"\"Load and preprocess image with robust error handling\"\"\"\n",
        "    try:\n",
        "        image_path = os.path.join(folder_path, f\"{image_id}.npy\")\n",
        "        img = np.load(image_path).astype(np.float32)\n",
        "\n",
        "        if len(img.shape) != 3 or img.shape[2] != 12:\n",
        "            return None\n",
        "\n",
        "        # Create output array\n",
        "        processed_img = np.zeros_like(img, dtype=np.float32)\n",
        "\n",
        "        # Process optical bands (0-3) with enhanced normalization\n",
        "        for band in range(4):\n",
        "            band_data = img[:, :, band]\n",
        "\n",
        "            # Remove outliers using percentile clipping\n",
        "            p2, p98 = np.percentile(band_data, [2, 98])\n",
        "            band_data = np.clip(band_data, p2, p98)\n",
        "\n",
        "            # Normalize to [0, 1]\n",
        "            if band_data.max() > band_data.min():\n",
        "                processed_img[:, :, band] = (band_data - band_data.min()) / (band_data.max() - band_data.min())\n",
        "            else:\n",
        "                processed_img[:, :, band] = 0.5\n",
        "\n",
        "        # Process SAR bands (4-11) with improved handling\n",
        "        for band in range(4, 12):\n",
        "            sar_data = img[:, :, band]\n",
        "\n",
        "            # Convert to dB scale with better handling of negative values\n",
        "            sar_linear = np.abs(sar_data) + 1e-10\n",
        "            sar_db = 10 * np.log10(sar_linear)\n",
        "\n",
        "            # Clip extreme values\n",
        "            p1, p99 = np.percentile(sar_db, [1, 99])\n",
        "            sar_db = np.clip(sar_db, p1, p99)\n",
        "\n",
        "            # Normalize\n",
        "            if sar_db.max() > sar_db.min():\n",
        "                processed_img[:, :, band] = (sar_db - sar_db.min()) / (sar_db.max() - sar_db.min())\n",
        "            else:\n",
        "                processed_img[:, :, band] = 0.5\n",
        "\n",
        "        return processed_img\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {image_id}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Enhanced data generator\n",
        "class EnhancedLandslideGenerator(Sequence):\n",
        "    def __init__(self, image_ids, labels, folder_path, batch_size=16,\n",
        "                 augment=False, shuffle=True, mixup_alpha=0.2):\n",
        "        super().__init__()\n",
        "        self.image_ids = image_ids\n",
        "        self.labels = labels\n",
        "        self.folder_path = folder_path\n",
        "        self.batch_size = batch_size\n",
        "        self.augment = augment\n",
        "        self.shuffle = shuffle\n",
        "        self.mixup_alpha = mixup_alpha\n",
        "\n",
        "        # Validate files\n",
        "        self.valid_indices = self._validate_files()\n",
        "        print(f\"Valid files: {len(self.valid_indices)}/{len(self.image_ids)}\")\n",
        "\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def _validate_files(self):\n",
        "        valid_indices = []\n",
        "        for idx, img_id in enumerate(self.image_ids):\n",
        "            file_path = os.path.join(self.folder_path, f\"{img_id}.npy\")\n",
        "            if os.path.exists(file_path):\n",
        "                try:\n",
        "                    test_img = np.load(file_path)\n",
        "                    if len(test_img.shape) == 3 and test_img.shape[2] == 12:\n",
        "                        valid_indices.append(idx)\n",
        "                except:\n",
        "                    continue\n",
        "        return valid_indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.valid_indices) / self.batch_size))\n",
        "\n",
        "    def custom_augment(self, img):\n",
        "        \"\"\"Custom augmentation for multi-channel images\"\"\"\n",
        "        if not self.augment:\n",
        "            return img\n",
        "\n",
        "        # Random horizontal flip\n",
        "        if np.random.random() < 0.5:\n",
        "            img = np.flip(img, axis=1)\n",
        "\n",
        "        # Random vertical flip\n",
        "        if np.random.random() < 0.5:\n",
        "            img = np.flip(img, axis=0)\n",
        "\n",
        "        # Random rotation (90, 180, 270 degrees)\n",
        "        if np.random.random() < 0.5:\n",
        "            k = np.random.randint(1, 4)\n",
        "            img = np.rot90(img, k=k, axes=(0, 1))\n",
        "\n",
        "        # Random brightness adjustment (only for optical bands 0-3)\n",
        "        if np.random.random() < 0.3:\n",
        "            brightness_factor = np.random.uniform(0.8, 1.2)\n",
        "            img[:, :, :4] = np.clip(img[:, :, :4] * brightness_factor, 0, 1)\n",
        "\n",
        "        # Light random noise\n",
        "        if np.random.random() < 0.2:\n",
        "            noise = np.random.normal(0, 0.005, img.shape).astype(np.float32)\n",
        "            img = np.clip(img + noise, 0, 1)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def mixup(self, x1, x2, y1, y2, alpha):\n",
        "        \"\"\"Apply mixup augmentation\"\"\"\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "        mixed_x = lam * x1 + (1 - lam) * x2\n",
        "        mixed_y = lam * y1 + (1 - lam) * y2\n",
        "        return mixed_x, mixed_y\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_indices = self.valid_indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "\n",
        "        for i in batch_indices:\n",
        "            img_id = self.image_ids[i]\n",
        "            label = self.labels[i]\n",
        "\n",
        "            img = load_and_preprocess_image(img_id, self.folder_path)\n",
        "            if img is not None:\n",
        "                img = self.custom_augment(img)\n",
        "                batch_images.append(img)\n",
        "                batch_labels.append(label)\n",
        "\n",
        "        if len(batch_images) == 0:\n",
        "            # Get actual image shape from first valid image\n",
        "            sample_shape = self._get_sample_shape()\n",
        "            batch_images = [np.zeros(sample_shape, dtype=np.float32)]\n",
        "            batch_labels = [0]\n",
        "\n",
        "        batch_images = np.array(batch_images, dtype=np.float32)\n",
        "        batch_labels = np.array(batch_labels, dtype=np.float32)\n",
        "\n",
        "        # Apply mixup for training\n",
        "        if self.augment and len(batch_images) >= 2 and np.random.random() < 0.3:\n",
        "            indices = np.random.permutation(len(batch_images))\n",
        "            mixed_images, mixed_labels = self.mixup(\n",
        "                batch_images, batch_images[indices],\n",
        "                batch_labels, batch_labels[indices],\n",
        "                self.mixup_alpha\n",
        "            )\n",
        "            return mixed_images, mixed_labels\n",
        "\n",
        "        return batch_images, batch_labels\n",
        "\n",
        "    def _get_sample_shape(self):\n",
        "        \"\"\"Get the shape of the first valid image\"\"\"\n",
        "        for i in self.valid_indices[:10]:  # Check first 10 valid indices\n",
        "            img_id = self.image_ids[i]\n",
        "            img = load_and_preprocess_image(img_id, self.folder_path)\n",
        "            if img is not None:\n",
        "                return img.shape\n",
        "        return (64, 64, 12)  # Default fallback\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.valid_indices)\n",
        "\n",
        "# Enhanced metrics\n",
        "def balanced_f1_score(y_true, y_pred):\n",
        "    \"\"\"Calculate balanced F1 score considering both classes\"\"\"\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "\n",
        "    # F1 for positive class\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    fp = K.sum(K.round(K.clip((1 - y_true) * y_pred, 0, 1)))\n",
        "    fn = K.sum(K.round(K.clip(y_true * (1 - y_pred), 0, 1)))\n",
        "\n",
        "    precision_pos = tp / (tp + fp + K.epsilon())\n",
        "    recall_pos = tp / (tp + fn + K.epsilon())\n",
        "    f1_pos = 2 * precision_pos * recall_pos / (precision_pos + recall_pos + K.epsilon())\n",
        "\n",
        "    # F1 for negative class\n",
        "    tn = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    precision_neg = tn / (tn + fn + K.epsilon())\n",
        "    recall_neg = tn / (tn + fp + K.epsilon())\n",
        "    f1_neg = 2 * precision_neg * recall_neg / (precision_neg + recall_neg + K.epsilon())\n",
        "\n",
        "    # Return macro F1\n",
        "    return (f1_pos + f1_neg) / 2\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    y_pred = K.round(K.clip(y_pred, 0, 1))\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return tp / (predicted_positives + K.epsilon())\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    y_pred = K.round(K.clip(y_pred, 0, 1))\n",
        "    tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return tp / (possible_positives + K.epsilon())\n",
        "\n",
        "# Enhanced loss functions\n",
        "def focal_loss(gamma=2.0, alpha=0.75):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        y_true = K.cast(y_true, 'float32')\n",
        "        y_pred = K.cast(K.clip(y_pred, K.epsilon(), 1 - K.epsilon()), 'float32')\n",
        "\n",
        "        ce_loss = -y_true * K.log(y_pred) - (1 - y_true) * K.log(1 - y_pred)\n",
        "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
        "        focal_weight = alpha * K.pow(1 - p_t, gamma)\n",
        "\n",
        "        return K.mean(focal_weight * ce_loss)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "def combined_loss(y_true, y_pred):\n",
        "    \"\"\"Combine focal loss with dice loss for better performance\"\"\"\n",
        "    focal = focal_loss(gamma=2.0, alpha=0.75)(y_true, y_pred)\n",
        "\n",
        "    # Dice loss component\n",
        "    smooth = 1e-6\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    dice_coeff = (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "    dice_loss = 1 - dice_coeff\n",
        "\n",
        "    return focal + 0.3 * dice_loss\n",
        "\n",
        "# Enhanced model architecture\n",
        "def create_enhanced_model(input_shape):\n",
        "    \"\"\"Create an enhanced CNN with attention mechanism\"\"\"\n",
        "    print(f\"Creating model with input shape: {input_shape}\")\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial conv block\n",
        "    x = Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(1e-4))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    def residual_block(x, filters, downsample=False):\n",
        "        shortcut = x\n",
        "        stride = 2 if downsample else 1\n",
        "\n",
        "        x = Conv2D(filters, (3, 3), strides=stride, padding='same',\n",
        "                   kernel_regularizer=l2(1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        x = Conv2D(filters, (3, 3), padding='same',\n",
        "                   kernel_regularizer=l2(1e-4))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "        if downsample or shortcut.shape[-1] != filters:\n",
        "            shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same',\n",
        "                             kernel_regularizer=l2(1e-4))(shortcut)\n",
        "            shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "        x = Add()([x, shortcut])\n",
        "        x = Activation('relu')(x)\n",
        "        x = Dropout(0.1)(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    # Adaptive feature extraction based on input size\n",
        "    current_size = input_shape[0]\n",
        "\n",
        "    if current_size >= 256:\n",
        "        # Full architecture for large images\n",
        "        x = residual_block(x, 64, downsample=True)   # /2\n",
        "        x = residual_block(x, 64)\n",
        "        x = residual_block(x, 128, downsample=True)  # /4\n",
        "        x = residual_block(x, 128)\n",
        "        x = residual_block(x, 256, downsample=True)  # /8\n",
        "        x = residual_block(x, 256)\n",
        "        x = residual_block(x, 512, downsample=True)  # /16\n",
        "    elif current_size >= 128:\n",
        "        # Medium architecture\n",
        "        x = residual_block(x, 64, downsample=True)   # /2\n",
        "        x = residual_block(x, 128, downsample=True)  # /4\n",
        "        x = residual_block(x, 256, downsample=True)  # /8\n",
        "        x = residual_block(x, 512, downsample=True)  # /16\n",
        "    else:\n",
        "        # Smaller architecture for small images (64x64)\n",
        "        x = residual_block(x, 64, downsample=True)   # /2 -> 32x32\n",
        "        x = residual_block(x, 128, downsample=True)  # /4 -> 16x16\n",
        "        x = residual_block(x, 256)                   # 16x16\n",
        "\n",
        "    # Simplified attention mechanism (optional, remove if causing issues)\n",
        "    try:\n",
        "        # Get current spatial dimensions\n",
        "        spatial_dims = x.shape[1] * x.shape[2]\n",
        "        channels = x.shape[3]\n",
        "\n",
        "        # Only apply attention if we have reasonable dimensions\n",
        "        if spatial_dims >= 4 and spatial_dims <= 1024 and channels >= 8:\n",
        "            # Reshape for attention\n",
        "            x_reshaped = Reshape((spatial_dims, channels))(x)\n",
        "\n",
        "            # Multi-head attention with reduced complexity\n",
        "            attention_output = MultiHeadAttention(\n",
        "                num_heads=min(8, channels // 8),\n",
        "                key_dim=min(64, channels // 4),\n",
        "                dropout=0.1\n",
        "            )(x_reshaped, x_reshaped)\n",
        "\n",
        "            attention_output = LayerNormalization()(attention_output + x_reshaped)\n",
        "\n",
        "            # Reshape back\n",
        "            x_attended = Reshape((x.shape[1], x.shape[2], channels))(attention_output)\n",
        "\n",
        "            # Combine original and attended features\n",
        "            x = Concatenate()([x, x_attended])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Attention mechanism failed, using standard processing: {e}\")\n",
        "\n",
        "    # Final processing\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    outputs = Dense(1, activation='sigmoid', dtype='float32', name='predictions')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare data with stratified split\n",
        "train_idx, val_idx = train_test_split(\n",
        "    np.arange(len(train_df)),\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=train_df['label']\n",
        ")\n",
        "\n",
        "# Calculate class weights\n",
        "class_weights = compute_class_weight(\n",
        "    'balanced',\n",
        "    classes=np.unique(train_df['label']),\n",
        "    y=train_df['label']\n",
        ")\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "print(f\"Class weights: {class_weight_dict}\")\n",
        "\n",
        "# Create generators\n",
        "train_gen = EnhancedLandslideGenerator(\n",
        "    image_ids=train_df['ID'].values[train_idx],\n",
        "    labels=train_df['label'].values[train_idx],\n",
        "    folder_path=train_data_path,\n",
        "    batch_size=8,\n",
        "    augment=True,\n",
        "    mixup_alpha=0.2\n",
        ")\n",
        "\n",
        "val_gen = EnhancedLandslideGenerator(\n",
        "    image_ids=train_df['ID'].values[val_idx],\n",
        "    labels=train_df['label'].values[val_idx],\n",
        "    folder_path=train_data_path,\n",
        "    batch_size=8,\n",
        "    augment=False\n",
        ")\n",
        "\n",
        "# Detect actual image shape\n",
        "print(\"Detecting image shape...\")\n",
        "actual_shape = train_gen._get_sample_shape()\n",
        "print(f\"Using input shape: {actual_shape}\")\n",
        "\n",
        "# Create and compile model with correct input shape\n",
        "model = create_enhanced_model(actual_shape)\n",
        "\n",
        "# FIXED: Use simple Adam optimizer with fixed learning rate to avoid scheduling conflicts\n",
        "optimizer = Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss=combined_loss,\n",
        "    metrics=['accuracy', precision_m, recall_m, balanced_f1_score]\n",
        ")\n",
        "\n",
        "print(f\"Model parameters: {model.count_params():,}\")\n",
        "\n",
        "# Custom learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "    \"\"\"Custom learning rate schedule\"\"\"\n",
        "    if epoch < 10:\n",
        "        return lr\n",
        "    elif epoch < 20:\n",
        "        return lr * 0.5\n",
        "    elif epoch < 30:\n",
        "        return lr * 0.25\n",
        "    else:\n",
        "        return lr * 0.1\n",
        "\n",
        "# Enhanced callbacks with fixed learning rate scheduling\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_landslide_model.keras',\n",
        "        monitor='val_balanced_f1_score',\n",
        "        mode='max',\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor='val_balanced_f1_score',\n",
        "        mode='max',\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    LearningRateScheduler(scheduler, verbose=1)  # Use custom scheduler instead of ReduceLROnPlateau\n",
        "]\n",
        "\n",
        "# Train model\n",
        "print(\"Starting training...\")\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    validation_data=val_gen,\n",
        "    epochs=50,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Load best model\n",
        "model.load_weights('best_landslide_model.keras')\n",
        "\n",
        "# Save the trained model for later use\n",
        "model.save('final_landslide_model.keras')\n",
        "print(\"Model training and saving completed!\")"
      ],
      "metadata": {
        "id": "BN3ohQ64cfyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BLOCK 2\n",
        "Predictions and Submission"
      ],
      "metadata": {
        "id": "n9i2yYZ8c0rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define paths (make sure these match your setup)\n",
        "test_data_path = '/content/drive/My Drive/test_data/'\n",
        "test_csv = \"/content/drive/My Drive/test_data/Test.csv\"\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('final_landslide_model.keras',\n",
        "                                  custom_objects={\n",
        "                                      'balanced_f1_score': balanced_f1_score,\n",
        "                                      'precision_m': precision_m,\n",
        "                                      'recall_m': recall_m,\n",
        "                                      'combined_loss': combined_loss\n",
        "                                  })\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv(test_csv)\n",
        "\n",
        "# Enhanced threshold optimization (using validation data from training)\n",
        "print(\"Optimizing decision threshold...\")\n",
        "val_predictions = []\n",
        "val_labels = []\n",
        "\n",
        "for i in range(len(val_gen)):\n",
        "    batch_x, batch_y = val_gen[i]\n",
        "    pred_batch = model.predict(batch_x, verbose=0)\n",
        "    val_predictions.extend(pred_batch.flatten())\n",
        "    val_labels.extend(batch_y.flatten())\n",
        "\n",
        "y_probs = np.array(val_predictions)\n",
        "y_true = np.array(val_labels)\n",
        "\n",
        "# Grid search for optimal threshold\n",
        "thresholds = np.arange(0.1, 0.9, 0.005)\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "best_metrics = {}\n",
        "\n",
        "for thresh in thresholds:\n",
        "    y_pred = (y_probs > thresh).astype(int)\n",
        "\n",
        "    # Calculate metrics for both classes\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_pos = f1_score(y_true, y_pred, pos_label=1)\n",
        "    f1_neg = f1_score(y_true, y_pred, pos_label=0)\n",
        "\n",
        "    # Optimize for balanced performance\n",
        "    balanced_score = f1_macro * 0.6 + min(f1_pos, f1_neg) * 0.4\n",
        "\n",
        "    if balanced_score > best_f1:\n",
        "        best_f1 = balanced_score\n",
        "        best_thresh = thresh\n",
        "        best_metrics = {\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_positive': f1_pos,\n",
        "            'f1_negative': f1_neg,\n",
        "            'balanced_score': balanced_score\n",
        "        }\n",
        "\n",
        "print(f\"\\nOptimal threshold: {best_thresh:.3f}\")\n",
        "print(f\"Best metrics: {best_metrics}\")\n",
        "\n",
        "# Final evaluation\n",
        "y_pred_final = (y_probs > best_thresh).astype(int)\n",
        "print(f\"\\nFinal Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_final,\n",
        "                          target_names=['No Landslide', 'Landslide']))\n",
        "\n",
        "# Generate test predictions\n",
        "print(\"Generating test predictions...\")\n",
        "test_predictions = []\n",
        "\n",
        "batch_size = 16\n",
        "for i in range(0, len(test_df), batch_size):\n",
        "    batch_ids = test_df['ID'].values[i:i+batch_size]\n",
        "    batch_imgs = []\n",
        "\n",
        "    for img_id in batch_ids:\n",
        "        img = load_and_preprocess_image(img_id, test_data_path)\n",
        "        if img is not None:\n",
        "            batch_imgs.append(img)\n",
        "        else:\n",
        "            batch_imgs.append(np.zeros(actual_shape, dtype=np.float32))\n",
        "\n",
        "    batch_imgs = np.array(batch_imgs)\n",
        "    probs = model.predict(batch_imgs, verbose=0).flatten()\n",
        "    preds = (probs > best_thresh).astype(int)\n",
        "    test_predictions.extend(preds)\n",
        "\n",
        "# Create submission\n",
        "submission_df = pd.DataFrame({\n",
        "    'ID': test_df['ID'],\n",
        "    'label': test_predictions\n",
        "})\n",
        "\n",
        "submission_df.to_csv('Enhanced_Landslide_Submission.csv', index=False)\n",
        "print(f\"Submission saved! Prediction distribution: {Counter(test_predictions)}\")\n",
        "\n",
        "# Plot training history (if history object is available)\n",
        "try:\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['balanced_f1_score'], label='Training F1')\n",
        "    plt.plot(history.history['val_balanced_f1_score'], label='Validation F1')\n",
        "    plt.title('Model F1 Score')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1 Score')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "except:\n",
        "    print(\"Could not plot training history - history object not available\")\n",
        "\n",
        "print(\"Prediction and submission completed successfully!\")"
      ],
      "metadata": {
        "id": "hz0zy5QEc2rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3DokAOmGcyPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AMOyjD4BczDa"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMIhJ5s/aXdO2wL1pgVkJRN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}